---
  network:
    name: 'default'
    head_params:
      hidden_layer_sizes:
        - 256
        - 256
      activation: 'relu'
      activate_final: False
    ppo_params:
      value_params:
        hidden_layer_sizes:
          - 256
          - 256
        activation: 'relu'
        activate_final: False
      policy_params:
        hidden_layer_sizes:
          - 256
          - 256
        activation: 'relu'
        activate_final: False
  train:
    name: 'Default'
    num_timesteps: 1000000
    episode_length: 1000
    action_repeat: 1
    num_envs: 1
    num_eval_envs: 10
    learning_rate: 0.0003
    entropy_cost: 0.0001
    discounting: 0.9
    seed: 0
    unroll_length: 10
    batch_size: 32
    num_minibatches: 32
    num_updates_per_batch: 4
    num_evals: 100
    num_resets_per_eval: 0
    normalize_observation: True
    normalize_advantage: True
    reward_scaling: 1.0
    clipping_epsilon: 0.3
    gae_lambda: 0.95
    deterministic_eval: False
    
