{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All environments registered successfully!\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "import os\n",
    "from utils.save_load import load_config, save_params, record, load_params\n",
    "from train.train_ppo import train_ppo\n",
    "from train.train_env import train_env\n",
    "from networks.ppo import make_ppo_network, make_ppo_policy\n",
    "from networks.networks import make_feed_forward, make_lstm\n",
    "from rendering.display import render_rollout, pretty_print_object\n",
    "from envs.custom_wrappers import CompleteAutoNormWrapper, HiddenStateWrapper, NetWrapper\n",
    "from brax.training.acme import running_statistics\n",
    "from utils.data_funcs import gather_rollout_data\n",
    "\n",
    "\n",
    "from brax import envs\n",
    "import jax\n",
    "import envs as _envs #don't remove this import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_FOLDER = '../'\n",
    "CONFIG_PATH = f\"{MAIN_FOLDER}configs/debug_config.yaml\"\n",
    "params = load_config(CONFIG_PATH)\n",
    "save_folder = f\"{MAIN_FOLDER}data/go1/{params['agent_network']['name']}\"\n",
    "network_param_path_save = f\"{save_folder}/network_params/\"\n",
    "env_param_path_save = f\"{save_folder}/env_params/\"\n",
    "rollout_path_save = f\"{save_folder}/rollouts/\"\n",
    "\n",
    "os.makedirs(network_param_path_save, exist_ok=True)\n",
    "os.makedirs(rollout_path_save, exist_ok=True)\n",
    "os.makedirs(env_param_path_save, exist_ok=True)\n",
    "\n",
    "ROLL_OUTS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = envs.get_environment(params['enviroment']['name'],**params['enviroment']['enviroment_params'], scene_path=f\"{MAIN_FOLDER}data/go1/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training already done/ Not enough rollouts\n"
     ]
    }
   ],
   "source": [
    "make_in_network_partial = partial(make_feed_forward,**params['env_network']['in_params'])\n",
    "make_out_network_partial = partial(make_feed_forward,**params['env_network']['out_params'])\n",
    "\n",
    "final_env_param_save = env_param_path_save+\"params.pkl\"\n",
    "\n",
    "if not os.path.exists(final_env_param_save) and os.path.exists(rollout_path_save+f\"rollout_{ROLL_OUTS}.pkl\"):\n",
    "    print('Starting training Env...')\n",
    "    \n",
    "    train_data = gather_rollout_data(rollout_path_save, ROLL_OUTS+1)\n",
    "\n",
    "    norm_params, env_network_params, type_params = train_env(train_data=train_data,make_in_part=make_in_network_partial, make_out_part=make_out_network_partial,environment=env, **params['env_train'], param_path=env_param_path_save)\n",
    "\n",
    "    save_params((norm_params,env_network_params, type_params), path=final_env_param_save)\n",
    "\n",
    "    print(\"Training complete\")\n",
    "else:\n",
    "    print(\"Training already done/ Not enough rollouts\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training PPO agent...\n",
      "No env params found\n",
      "Defaulting to Feed Forward network head\n",
      "\n",
      "            Time: 0:00:00\n",
      "\n",
      "            Total Steps Taken: 0\n",
      "\n",
      "            Training Steps Per Second: 0.00\n",
      "\n",
      "            Evaluation Metrics:\n",
      "            - Episode Rewards:\n",
      "            - Latest Reward: -0.21\n",
      "            - Standard Deviation: 0.01\n",
      "            - Maximum Recorded Reward: -0.21\n",
      "\n",
      "            --------------------------------------------\n",
      "            \n",
      "\n",
      "            Time: 0:07:13.565209\n",
      "\n",
      "            Total Steps Taken: 112640\n",
      "\n",
      "            Training Steps Per Second: 261.03\n",
      "\n",
      "            Evaluation Metrics:\n",
      "            - Episode Rewards:\n",
      "            - Latest Reward: -0.21\n",
      "            - Standard Deviation: 0.01\n",
      "            - Maximum Recorded Reward: -0.21\n",
      "\n",
      "            --------------------------------------------\n",
      "            \n",
      "Saving params... name:default steps:112640\n",
      "\n",
      "            Time: 0:12:19.128774\n",
      "\n",
      "            Total Steps Taken: 225280\n",
      "\n",
      "            Training Steps Per Second: 371.26\n",
      "\n",
      "            Evaluation Metrics:\n",
      "            - Episode Rewards:\n",
      "            - Latest Reward: -0.21\n",
      "            - Standard Deviation: 0.01\n",
      "            - Maximum Recorded Reward: -0.21\n",
      "\n",
      "            --------------------------------------------\n",
      "            \n",
      "Saving params... name:default steps:225280\n"
     ]
    }
   ],
   "source": [
    "make_ppo_network_partial = partial(make_ppo_network,\n",
    "                            head_name = params['agent_network']['name'],        \n",
    "                            head_params = params['agent_network']['head_params'],\n",
    "                            value_params = params['agent_network']['ppo_params']['value_params'],\n",
    "                            policy_params = params['agent_network']['ppo_params']['policy_params'])\n",
    "\n",
    "final_param_save = network_param_path_save+\"params.pkl\"\n",
    "\n",
    "if not os.path.exists(final_param_save):\n",
    "    print('Starting training PPO agent...')\n",
    "\n",
    "    if os.path.exists(final_env_param_save):\n",
    "        print('Loading env params')\n",
    "        env_params = load_params(final_env_param_save)\n",
    "    else:\n",
    "        print('No env params found')\n",
    "        env_params = None\n",
    "            \n",
    "    mk_policy, norm_params, policy_params, wrap_params ,metrics = train_ppo(make_ppo_network_partial=make_ppo_network_partial,make_in_part=make_in_network_partial,make_out_part=make_out_network_partial,environment=env, **params['agent_train'], param_path=network_param_path_save, env_params=env_params)\n",
    "\n",
    "    save_params((norm_params,policy_params), path=final_param_save)\n",
    "\n",
    "    print(\"Training complete\")\n",
    "else:\n",
    "    print(\"Training already done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import numpy as jp\n",
    "import functools\n",
    "\n",
    "if not os.path.exists(rollout_path_save+f\"rollout_{ROLL_OUTS}.pkl\"):\n",
    "\n",
    "    print(\"Loading parameters\")\n",
    "\n",
    "    ppo_net = make_ppo_network_partial(\n",
    "        input = env.observation_size,\n",
    "        output = env.action_size)\n",
    "\n",
    "    norm_params,policy_params = load_params(final_param_save)\n",
    "\n",
    "    \n",
    "\n",
    "    if os.path.exists(final_env_param_save):\n",
    "        print('Loading env params')\n",
    "        env_params = load_params(final_env_param_save)\n",
    "        types = jp.stack(env_params[2]['params']['0'], axis=0)\n",
    "        type_mean = jp.mean(types, axis=0)\n",
    "        type_cov =  jp.cov(types.T)\n",
    "\n",
    "        type_dist_fn = functools.partial(jax.random.multivariate_normal, mean=type_mean, cov=type_cov)\n",
    "\n",
    "        test_type = type_dist_fn(jax.random.PRNGKey(0))\n",
    "\n",
    "        assert float('nan') != test_type[0], 'not enough data for a cov matrix'\n",
    "\n",
    "        in_net = make_in_network_partial(\n",
    "            input_size = env.action_size + types.size,\n",
    "            output_size = env.action_size)\n",
    "        \n",
    "        out_net = make_out_network_partial(\n",
    "            input_size = env.vel_pos + types.size,\n",
    "            output_size = env.vel_pos)\n",
    "        \n",
    "        gen_func = jax.jit(env.pipeline_init)\n",
    "        \n",
    "        wrap_params = (in_net, out_net, env_params[1][0], env_params[1][1], env_params[0], type_dist_fn, gen_func)\n",
    "        print('Env params loaded')\n",
    "    else:\n",
    "        print('No env params found')\n",
    "        wrap_params = None\n",
    "\n",
    "    env = HiddenStateWrapper(env)\n",
    "\n",
    "    if wrap_params is not None:\n",
    "        env = NetWrapper(env, *wrap_params)\n",
    "\n",
    "    env = CompleteAutoNormWrapper(env, running_statistics.normalize ,norm_params)\n",
    "\n",
    "    policy = make_ppo_policy(policy_params, ppo_net)\n",
    "    \n",
    "    j_reset = jax.jit(env.reset)\n",
    "    j_step = jax.jit(env.step)\n",
    "    j_policy = jax.jit(policy)\n",
    "\n",
    "    for rng in range(ROLL_OUTS+1):\n",
    "        print(f\"Rollout {rng}\")\n",
    "        data = record(j_reset, j_step, j_policy, rng, path=rollout_path_save)\n",
    "\n",
    "        if rng % (max(ROLL_OUTS//5,1)) == 0:\n",
    "            render_rollout(env, data[0], 1 ,title=f\"Rollout {params['agent_network']['name']} {rng}\")\n",
    "\n",
    "else:\n",
    "    print(\"Rollouts already done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mujoco_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
